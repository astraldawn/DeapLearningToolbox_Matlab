=============================
ROUND 1
- LR 0.001
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.00046512
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.60232
Full-batch train err = 0.55195
Full-batch val err = 1.7796
Classification Error on Training Set 14.5979
Classification Error on Validation Set 57.7041


Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.2227 0.0714 0.2238 0.6480 0.3078 0.4892 0.3871]
               prec: [0.2600 0.8000 0.3255 0.4945 0.3116 0.5884 0.3456]
           clsfRate: 0.4007
                 f1: [0.2399 0.1311 0.2652 0.5609 0.3097 0.5342 0.3652]
                UAR: 0.3357
    confusionMatrix: [7 x 7 double]

=============================
ROUND 2
- LR 0.005
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.0033333
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.27472
Full-batch train err = 0.20327
Full-batch val err = 2.3458
Classification Error on Training Set 5.5374
Classification Error on Validation Set 57.3419

Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.2527 0.0179 0.1935 0.6358 0.2374 0.5928 0.4432]
               prec: [0.2921 0.5000 0.2645 0.5429 0.3312 0.4970 0.3325]
           clsfRate: 0.4051
                 f1: [0.2710 0.0345 0.2235 0.5857 0.2765 0.5407 0.3799]
                UAR: 0.3390
    confusionMatrix: [7×7 double]
=============================
ROUND 3
- LR 0.0005
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.00018868
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.93694
Full-batch train err = 0.90987
Full-batch val err = 1.6137
Classification Error on Training Set 29.5064
Classification Error on Validation Set 59.0972


Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.2463 0.0893 0.2641 0.6425 0.2358 0.5349 0.4152]
               prec: [0.2868 1 0.3025 0.5098 0.3143 0.5401 0.3495]
           clsfRate: 0.4051
                 f1: [0.2650 0.1639 0.2820 0.5685 0.2695 0.5375 0.3795]
                UAR: 0.3469
    confusionMatrix: [7×7 double]

=============================
ROUND 4
- LR 0.0025
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.0013514
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.20391
Full-batch train err = 0.17256
Full-batch val err = 2.283
Classification Error on Training Set 2.9061
Classification Error on Validation Set 57.927


Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.3191 0.0893 0.2177 0.6380 0.2221 0.5205 0.3970]
               prec: [0.2637 0.7143 0.2762 0.5196 0.3152 0.5427 0.3602]
           clsfRate: 0.3998
                 f1: [0.2888 0.1587 0.2435 0.5727 0.2606 0.5314 0.3777]
                UAR: 0.3434
    confusionMatrix: [7×7 double]

=============================
ROUND 5
- LR 0.01
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.0071429
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.42983
Full-batch train err = 0.38404
Full-batch val err = 2.5615
Classification Error on Training Set 13.1568
Classification Error on Validation Set 59.543


Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.1478 0.0357 0.2218 0.6615 0.4257 0.5108 0.3937]
               prec: [0.3557 0.6667 0.3198 0.5157 0.3251 0.6092 0.3429]
           clsfRate: 0.4185
                 f1: [0.2088 0.0678 0.2619 0.5795 0.3687 0.5557 0.3666]
                UAR: 0.3424
    confusionMatrix: [7×7 double]

============================
ROUND 6
- LR 0.00075
- Momentum 0.5 (0.95)

Training NN with 3 layers
Topology = 500  250    7
Activation Functions:
    'ReLu'    'ReLu'    'softmax'

Batchsize = 100
Training method: SGD with momentum
Global learning rate = 0.0003
momentum = 0.95

Max norm constraint is applied with max norm = 4

No Dropout used

Mini-batch mean error on training set is 0.68457
Full-batch train err = 0.64547
Full-batch val err = 1.6999
Classification Error on Training Set 18.0693
Classification Error on Validation Set 58.0663


Activation Statistics - Mean values should be different than 0
Layer 1 (ReLu) mean / st.dev of activations on training set 0.64852 / 0.92876
Layer 2 (ReLu) mean / st.dev of activations on training set 0.62633 / 0.90878
Layer 3 (softmax) mean / st.dev of activations on training set 0.14286 / 0.23237

Weight Statistics - Ratio should be between 0.01 and 0.0001
Layer 1 Ratio of weight updates over weights magnitudes, mean / st.dev. over all mini-batches 0.00010783 / 5.5902e-06
Layer 2 Ratio of weight updates over weights magnitudes, mean / st.dev. over all mini-batches 0.00010762 / 7.9858e-06
Layer 3 Ratio of weight updates over weights magnitudes, mean / st.dev. over all mini-batches 0.00015416 / 1.6836e-05

Validation error has increased 20 times since the minimun validation error observed so training will stop

ans =

  struct with fields:

             recall: [0.2227 0.1071 0.2460 0.6592 0.2894 0.5470 0.3921]
               prec: [0.3114 0.7500 0.3427 0.4946 0.3005 0.5537 0.3612]
           clsfRate: 0.4113
                 f1: [0.2597 0.1875 0.2864 0.5651 0.2949 0.5503 0.3760]
                UAR: 0.3519
    confusionMatrix: [7×7 double]
